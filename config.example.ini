[PROXY]
host = 127.0.0.1
port = 10808
enabled = false

[API_KEYS]
gpt_api_key = your_openai_api_key_here
claude_api_key = your_anthropic_api_key_here
gemini_api_key = your_google_api_key_here
modelscope_api_key = your_modelscope_token_here
custom_openai_api_key = your_custom_api_key_here
siliconflow_api_key = your_siliconflow_api_key_here

[MODELS]
gpt_model = gpt-4-turbo
claude_model = claude-3-opus-20240229
gemini_model = gemini-2.0-flash
modelscope_model = deepseek-ai/DeepSeek-R1
custom_openai_model = your_custom_model_name_here
ollama_model = llama3.2
siliconflow_model = deepseek-ai/DeepSeek-R1

[CUSTOM_OPENAI]
api_url = https://your-custom-api-endpoint.com/v1/chat/completions

[CUSTOM_OPENAI_MODELS]
models = [{"name": "deepseek-ai/DeepSeek-R1", "api_key": "自己的key", "model_name": "deepseek-ai/DeepSeek-R1", "api_url": "https://api.siliconflow.cn/v1/chat/completions"}]
enabled = true

[SILICONFLOW]
api_url = https://api.siliconflow.cn/v1/chat/completions

[OLLAMA]
api_url = http://localhost:11434/api/chat

[EMBEDDING_MODELS]
siliconflow_embedding_model = BAAI/bge-m3 ; 示例：Siliconflow 向量模型的名称

[USER_PREFERENCES]
last_selected_model = Gemini

